{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Purpose\n",
    ">### EDA with image, and find out some way(or feature) can let model get better performance\n",
    ">##### Reference:&emsp;[OpenCV Image Thresholding](https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [1. Import Packages](#1.-Import-Packages)\n",
    "* [2. Set Direction and Find the File Path](#2.-Set-Direction-and-Find-the-File-Path)\n",
    "* [3. Basic EDA](#3.-Basic-EDA)\n",
    "    * [3.1 EDA with Color Image](#3.1-EDA-with-Color-Image)\n",
    "    * [3.2 EDA with Gray Image](#3.2-EDA-with-Gray-Image)\n",
    "* [4. Final Thought](#4.-Final-Thought)\n",
    "    * [4.1 Let Middle Image Cover by Right Image's Black Pixel](#4.1-Let-Middle-Image-Cover-by-Right-Image's-Black-Pixel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Direction and Find the File Path\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deed_name = ['AA', 'AD', 'AG', 'BA', 'BD', 'BG', 'EA', 'ED', 'EG', 'HA', 'HD',\n",
    "             'HG', 'LA', 'LG', 'PA', 'PG', 'QA', 'QG', 'RA', 'RG', 'UA', 'UD', 'UG', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_file_name = ['P2_OK_P4', 'P3_OK_P4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_deed_dir = \"//Srvappweb-t/f$/{}/{}/\".format(deed_name[1], ok_file_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find direction\n",
    "ok_deed_dir_li = []\n",
    "for i in range(len(deed_name)):\n",
    "    for t in range(len(ok_file_name)):\n",
    "        ok_deed_dir = \"//Srvappweb-t/f$/{}/{}/\".format(deed_name[i], ok_file_name[t])\n",
    "        ok_deed_dir_li.append(ok_deed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find file name\n",
    "img_path_list = []\n",
    "for ok_deed_dir in ok_deed_dir_li:\n",
    "    for file_path in glob('{}/*.jpg'.format(ok_deed_dir)):\n",
    "        img_path_list.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//Srvappweb-t/f$/AA/P2_OK_P4\\\\AB002-AA0769076.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check path list\n",
    "img_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ok deed: 69912\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of ok deed: {len(img_path_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic EDA\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 EDA with Color Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_path_list[16599])\n",
    "\n",
    "# The method returns two outputs. The first is the threshold that was used and the second output is the thresholded image.\n",
    "# you also can use 'cv.threshold(img_color, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)'\n",
    "# Otsu's method avoids having to choose a value and determines it automatically.\n",
    "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)  \n",
    "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img,50,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,150,255,cv.THRESH_TOZERO_INV)\n",
    "# thresh6 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 33, 8)\n",
    "# thresh7 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 33, 8)\n",
    "\n",
    "# titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV', 'adaptiveThreshold', 'adaptiveThresholdINV']\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "# images = [img, thresh1, thresh2, thresh3, thresh4, thresh5, thresh6, thresh7]\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "n = 6\n",
    "for i in range(n):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    original_img = cv.cvtColor(images[i],cv.COLOR_BGR2RGB)\n",
    "    plt.imshow(original_img)    \n",
    "    \n",
    "#     if i == 0:\n",
    "#         original_img = cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB)\n",
    "#         plt.imshow(original_img)\n",
    "#     else:\n",
    "#         plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 EDA with Gray Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deed = img_path_list[16599]\n",
    "\n",
    "img = cv.imread(deed)\n",
    "img_gray = cv.imread(deed, 0)\n",
    "\n",
    "ret,thresh1 = cv.threshold(img_gray,127,255,cv.THRESH_BINARY)  # +cv2.THRESH_OTSU\n",
    "ret,thresh2 = cv.threshold(img_gray,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img_gray,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img_gray,50,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img_gray,150,255,cv.THRESH_TOZERO_INV)\n",
    "thresh6 = cv.adaptiveThreshold(img_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 33, 8)\n",
    "thresh7 = cv.adaptiveThreshold(img_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 33, 8)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV', 'adaptiveThreshold', 'adaptiveThresholdINV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5, thresh6, thresh7]\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "n = 8\n",
    "for i in range(n):\n",
    "    plt.subplot(3,3,i+1)  \n",
    "    \n",
    "    if i == 0:\n",
    "        original_img = cv.cvtColor(images[i],cv.COLOR_BGR2RGB)\n",
    "        plt.imshow(original_img)\n",
    "    else:\n",
    "        plt.imshow(images[i],'gray')\n",
    "        \n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Thought\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I think 'adaptiveThreshold gray image' can mask on 'BINARY color image', and that wiil be a good image for analysis. It showing deed with white background. Handwrite and Print Fonts will be same color which is black. The other part will be different from black and white. (by the way, simplify image color but remaind importent color alone is a way to extract feature we need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deed = img_path_list[16599]\n",
    "\n",
    "img_color = cv.imread(deed)\n",
    "img_gray = cv.imread(deed, 0)\n",
    "\n",
    "\n",
    "ret,thresh1 = cv.threshold(img_color,95,255,cv.THRESH_BINARY)  # +cv2.THRESH_OTSU\n",
    "thresh2 = cv.adaptiveThreshold(img_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 33, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Original_Image','BINARY', 'adaptiveThreshold']\n",
    "images = [img_color, thresh1, thresh2]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "n = len(images)\n",
    "for i in range(n):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    if i in [0,1]:\n",
    "        img = cv.cvtColor(images[i],cv.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "         plt.imshow(images[i],'gray')\n",
    "\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Let Middle Image Cover by Right Image's Black Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_li = thresh2.flatten().tolist()\n",
    "indices = [i for i, x in enumerate(flatten_li) if x == 0]\n",
    "\n",
    "\n",
    "width = thresh2.shape[1]\n",
    "\n",
    "all_index_li = []\n",
    "for i in indices:\n",
    "    index_li = [None, None]\n",
    "    # return row index\n",
    "    index_li[1] = i%width\n",
    "    # return column index\n",
    "    index_li[0] = int(i/width)\n",
    "    \n",
    "    all_index_li.append(index_li)\n",
    "\n",
    "for i in range(len(all_index_li)):\n",
    "    thresh1[all_index_li[i][0]][all_index_li[i][1]]=[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Original_Image','Final_Image']\n",
    "images = [img_color, thresh1]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "n = len(images)\n",
    "for i in range(n):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    if i in [0,1]:\n",
    "        img = cv.cvtColor(images[i],cv.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "         plt.imshow(images[i],'gray')\n",
    "    \n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
