{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Purpose\n",
    ">### First, using kmeans to simplify image color, and seperate two type of color.<br><br> Second, caculating light pixel and dark pixel number to predict image whether is cover by white paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [1. Import Packages](#1.-Import-Packages)\n",
    "* [2. Useful Function](#2.-Useful-Function)\n",
    "* [3. Set Direction and Find the File Path](#3.-Set-Direction-and-Find-the-File-Path)\n",
    "* [4. Model Build by Image Threshold and cv.kmean](#4.-Model-Build-by-Image-Threshold-and-cv.kmean)\n",
    "    * [4.1 Save Model Result](#4.1-Save-Model-Result)\n",
    "    * [4.2 Load Model Result](#4.2-Load-Model-Result)    \n",
    "    * [4.3 Final Dataframe](#4.3-Final-Dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages   \n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "# example of pixel normalization\n",
    "from numpy import asarray\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful Function\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to check if two to get unique values from list using traversal function to get unique values \n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    # print list\n",
    "    li = []\n",
    "    for x in unique_list: \n",
    "        li.append(x)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Code to find rank of elements \n",
    "def rankify(A): \n",
    "  \n",
    "    # Rank Vector \n",
    "    R = [0 for x in range(len(A))] \n",
    "  \n",
    "    # Sweep through all elements in A for each element count the number of less than and equal elements separately in r and s. \n",
    "    for i in range(len(A)): \n",
    "        (r, s) = (1, 1) \n",
    "        for j in range(len(A)): \n",
    "            if j != i and A[j] < A[i]: \n",
    "                r += 1\n",
    "            if j != i and A[j] == A[i]: \n",
    "                s += 1       \n",
    "\n",
    "        # Use formula to obtain rank \n",
    "        R[i] = r + (s - 1) / 2\n",
    "  \n",
    "    # Return Rank Vector \n",
    "    return R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Direction and Find the File Path\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deed_name = ['AA', 'AD', 'AG', 'BA', 'BD', 'BG', 'EA', 'ED', 'EG', 'HA', 'HD',\n",
    "             'HG', 'LA', 'LG', 'PA', 'PG', 'QA', 'QG', 'RA', 'RG', 'UA', 'UD', 'UG', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_file_name = ['P2_OK_P4', 'P3_OK_P4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_deed_dir = \"//Srvappweb-t/f$/{}/{}/\".format(deed_name[1], ok_file_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_deed_dir_li = []\n",
    "for i in range(len(deed_name)):\n",
    "    for t in range(len(ok_file_name)):\n",
    "        ok_deed_dir = \"//Srvappweb-t/f$/{}/{}/\".format(deed_name[i], ok_file_name[t])\n",
    "        ok_deed_dir_li.append(ok_deed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = []\n",
    "for ok_deed_dir in ok_deed_dir_li:\n",
    "    for file_path in glob('{}/*.jpg'.format(ok_deed_dir)):\n",
    "        img_path_list.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//Srvappweb-t/f$/AA/P2_OK_P4\\\\AB002-AA0769076.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Number of ok deed: {len(img_path_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Build by Image Threshold and cv.kmean\n",
    "[Go back to the Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### algorithm:\n",
    ">step1. read image<br>\n",
    "step2. using two threshold method(THRESH_BINARY & ADAPTIVE_THRESH_GAUSSIAN_C + THRESH_BINARY) to create two new images(thresh1 & thresh2)<br>\n",
    "step3. let thresh1 cover by thresh2 black pixel<br>\n",
    "step4. resize image to (675, 900)<br>\n",
    "step5. cut image around itself<br>\n",
    "step6. using kmeans to merge similar color (k = 3)<br>\n",
    "step7. find 3 color RGB list<br>\n",
    "step7. calculate brightness depend on the 3 color (sum of RGB values)<br>\n",
    "step8. according to brightness, define color to light color or dark color (dop color which brightness was middle)<br>\n",
    "step9. count how many pixel is light color(or dark color)<br>\n",
    "step10. caculate light dark ratio (light color/dark color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69912/69912 [44:23:43<00:00,  2.29s/it]    \n"
     ]
    }
   ],
   "source": [
    "# 查看類別資料夾裡的資料\n",
    "result_light_pixel_count = []\n",
    "result_dark_pixel_count = []\n",
    "result_light_dark_ratio = []\n",
    "for i in tqdm(range(len(img_path_list))):\n",
    "    deed = img_path_list[i]\n",
    "\n",
    "    img_color = cv.imread(deed) # read RGB image\n",
    "    img_gray = cv.imread(deed, 0) # read gray image\n",
    "    # The method returns two outputs. The first is the threshold that was used and the second output is the thresholded image.\n",
    "    ret,thresh1 = cv.threshold(img_color, 95, 255, cv.THRESH_BINARY)\n",
    "    thresh2 = cv.adaptiveThreshold(img_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 33, 8)\n",
    "\n",
    "    # find black pixel(value=0), and save index\n",
    "    flatten_li = thresh2.flatten().tolist()\n",
    "    indices = [i for i, x in enumerate(flatten_li) if x == 0]  # find which pixel is black\n",
    "    \n",
    "    # let thresh1 cover by thresh2 black pixel\n",
    "    width = thresh2.shape[1] \n",
    "    all_index_li = []\n",
    "    for i in indices:\n",
    "        index_li = [None, None]\n",
    "        # return row index\n",
    "        index_li[1] = i%width\n",
    "        # return column index\n",
    "        index_li[0] = int(i/width)\n",
    "\n",
    "        all_index_li.append(index_li)\n",
    "\n",
    "    for i in range(len(all_index_li)):\n",
    "        thresh1[all_index_li[i][0]][all_index_li[i][1]]=[0, 0, 0]\n",
    "\n",
    "    img = cv.cvtColor(thresh1, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    img = cv.resize(img,(675, 900))\n",
    "\n",
    "\n",
    "    ######## cut image\n",
    "    # 裁切區域的 x 與 y 座標（左上角）\n",
    "    x = 100\n",
    "    y = 30\n",
    "    # 裁切區域的長度與寬度\n",
    "    w = 525\n",
    "    h = 770\n",
    "    # 裁切圖片\n",
    "    cut_img = img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "    Z = cut_img.reshape((-1,3))\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "\n",
    "\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 0.5)\n",
    "    K=3\n",
    "    ret, label1, center1 = cv.kmeans(Z, K, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "    center1 = np.uint8(center1)\n",
    "    res1 = center1[label1.flatten()]\n",
    "    output1 = res1.reshape((cut_img.shape))\n",
    "    # output1為 k-means 後的圖片結果 shape為(770, 525, 3)\n",
    "    # 所以先攤平，在3個3個當作pixel的值，並取出\n",
    "    li = output1.flatten().tolist()\n",
    "    flatten_li = []\n",
    "    for i in range(len(li)):\n",
    "        if (i+1)%3 == 0:  \n",
    "            flatten_li.append(li[i-2:i+1])\n",
    "\n",
    "\n",
    "    unique_li = unique(flatten_li)\n",
    "    bright = []\n",
    "    for i in range(len(unique_li)):\n",
    "        temp = 0\n",
    "        for t in range(len(unique_li[i])):\n",
    "            temp = temp + unique_li[i][t]\n",
    "        bright.append(temp)\n",
    "\n",
    "        rank_li = rankify(bright) # 亮度越大，排名越大\n",
    "\n",
    "\n",
    "    color_type_li = []\n",
    "    for i in rank_li:\n",
    "        ########################################################################\n",
    "        if i==3:\n",
    "        ########################################################################\n",
    "            color_type_li.append('light_color')\n",
    "        ########################################################################\n",
    "        elif i==1:\n",
    "        #########################################################################    \n",
    "            color_type_li.append('dark_color')\n",
    "        else:\n",
    "            color_type_li.append('neutral color')\n",
    "\n",
    "\n",
    "    RGB_df = pd.DataFrame(unique_li, columns=['R', 'G', 'B'])\n",
    "    color_df = pd.DataFrame(color_type_li, columns = ['color_type'])\n",
    "    color_type_df = pd.concat([RGB_df, color_df], axis = 1)\n",
    "    color_type_df = color_type_df.astype({'R': int, 'G': int, 'B': int})\n",
    "\n",
    "    light_color_min = (int(color_type_df[color_type_df.color_type=='light_color'].R.min()), \n",
    "                       int(color_type_df[color_type_df.color_type=='light_color'].G.min()), \n",
    "                       int(color_type_df[color_type_df.color_type=='light_color'].B.min()))\n",
    "\n",
    "    light_color_max = (int(color_type_df[color_type_df.color_type=='light_color'].R.max()), \n",
    "                       int(color_type_df[color_type_df.color_type=='light_color'].G.max()), \n",
    "                       int(color_type_df[color_type_df.color_type=='light_color'].B.max()))\n",
    "\n",
    "    dark_color_min = (int(color_type_df[color_type_df.color_type=='dark_color'].R.min()), \n",
    "                      int(color_type_df[color_type_df.color_type=='dark_color'].G.min()), \n",
    "                      int(color_type_df[color_type_df.color_type=='dark_color'].B.min()))\n",
    "\n",
    "    dark_color_max = (int(color_type_df[color_type_df.color_type=='dark_color'].R.max()), \n",
    "                      int(color_type_df[color_type_df.color_type=='dark_color'].G.max()), \n",
    "                      int(color_type_df[color_type_df.color_type=='dark_color'].B.max()))\n",
    "\n",
    "    # return 一個值為 0 或 255的矩陣\n",
    "    light_pixel = cv.inRange(output1, light_color_min, light_color_max)\n",
    "    dark_pixel = cv.inRange(output1, dark_color_min, dark_color_max)\n",
    "    light_dark_ratio = (light_pixel!=0).sum()/(dark_pixel!=0).sum()\n",
    "\n",
    "    result_light_pixel_count.append(int((light_pixel!=0).sum()))\n",
    "    result_dark_pixel_count.append(int((dark_pixel!=0).sum()))\n",
    "    result_light_dark_ratio.append(light_dark_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Save Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list(cutted word data) to a json file\n",
    "with open(\"./result_light_pixel_count_2.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file more\n",
    "    # human-readable for more complicated data\n",
    "    json.dump(result_light_pixel_count, f, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list(cutted word data) to a json file\n",
    "with open(\"./result_dark_pixel_count_2.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file more \n",
    "    # human-readable for more complicated data\n",
    "    json.dump( result_dark_pixel_count, f, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list(cutted word data) to a json file\n",
    "with open(\"./result_light_dark_ratio_2.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file more \n",
    "    # human-readable for more complicated data\n",
    "    json.dump(result_light_dark_ratio, f, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Load Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file to a list\n",
    "with open('./result_dark_pixel_count_2.json', 'r') as f:\n",
    "     result_dark_pixel_count = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file to a list\n",
    "with open('./result_light_pixel_count_2.json', 'r') as f:\n",
    "    result_light_pixel_count = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file to a list\n",
    "with open('./result_light_dark_ratio_2.json', 'r') as f:\n",
    "    result_light_dark_ratio = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = pd.DataFrame(img_path_list, columns = ['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_light_pixel_count_df = pd.DataFrame(result_light_pixel_count, columns = ['result_light_pixel_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dark_pixel_count_df = pd.DataFrame(result_dark_pixel_count, columns = ['result_dark_pixel_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_light_dark_ratio_df = pd.DataFrame(result_light_dark_ratio, columns = ['result_light_dark_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([path_df, result_light_pixel_count_df, result_dark_pixel_count_df, result_light_dark_ratio_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>result_light_pixel_count</th>\n",
       "      <th>result_dark_pixel_count</th>\n",
       "      <th>result_light_dark_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>//Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769076.jpg</td>\n",
       "      <td>311113</td>\n",
       "      <td>54730</td>\n",
       "      <td>5.684506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>//Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769077.jpg</td>\n",
       "      <td>312220</td>\n",
       "      <td>54334</td>\n",
       "      <td>5.746310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769078.jpg</td>\n",
       "      <td>311719</td>\n",
       "      <td>55292</td>\n",
       "      <td>5.637687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>//Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769097.jpg</td>\n",
       "      <td>306306</td>\n",
       "      <td>61059</td>\n",
       "      <td>5.016558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>//Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0816252.jpg</td>\n",
       "      <td>296854</td>\n",
       "      <td>67558</td>\n",
       "      <td>4.394061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path  result_light_pixel_count  \\\n",
       "0  //Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769076.jpg                    311113   \n",
       "1  //Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769077.jpg                    312220   \n",
       "2  //Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769078.jpg                    311719   \n",
       "3  //Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0769097.jpg                    306306   \n",
       "4  //Srvappweb-t/f$/AA/P2_OK_P4\\AB002-AA0816252.jpg                    296854   \n",
       "\n",
       "   result_dark_pixel_count  result_light_dark_ratio  \n",
       "0                    54730                 5.684506  \n",
       "1                    54334                 5.746310  \n",
       "2                    55292                 5.637687  \n",
       "3                    61059                 5.016558  \n",
       "4                    67558                 4.394061  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_dark = int(result_dark_pixel_count_df.result_dark_pixel_count.mean()-1*result_dark_pixel_count_df.result_dark_pixel_count.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_light = int(result_light_pixel_count_df.result_light_pixel_count.mean()+1*result_light_pixel_count_df.result_light_pixel_count.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df[(final_df.result_light_dark_ratio>=30) & (final_df.result_light_pixel_count>=threshold_light) & (final_df.result_dark_pixel_count<=threshold_dark)]\n",
    "path_li_with_several_condition = test_df.path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df[(final_df.result_light_dark_ratio>=22.5)]\n",
    "path_li_with_several_condition = test_df.path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'number of deed which is cover by white paper: {len(path_li_with_several_condition)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (100,100)\n",
    "if len(path_li_with_several_condition)<=20:\n",
    "    n = len(path_li_with_several_condition)\n",
    "else:\n",
    "    n =len(path_li_with_several_condition)\n",
    "image = random.sample(path_li_with_several_condition, n)\n",
    "for i, img in enumerate(image): \n",
    "    img = cv.imread(img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,80)\n",
    "    plt.subplot(int(n/2)+1, 2, i+1)\n",
    "    \n",
    "    plt.imshow(img, aspect='auto')\n",
    "\n",
    "#     plt.title(titles[i])\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = final_df[(final_df.result_light_pixel_count>=(1.4*threshold_light))]\n",
    "# path_li = test_df.path.tolist()\n",
    "# final_path_li = []\n",
    "# for i in range(len(path_li)):\n",
    "#     if path_li[i].find('/AD/') == -1 and path_li[i].find('/ED/') == -1:\n",
    "#         final_path_li.append(path_li[i])\n",
    "#     else:\n",
    "#         pass\n",
    "# path_li_with_several_condition = final_path_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = final_df[(final_df.result_dark_pixel_count<=(0.4*threshold_dark))]\n",
    "# path_li_with_several_condition = test_df.path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = final_df[(final_df.result_dark_pixel_count<=(1.15*threshold_dark))]\n",
    "# path_li = test_df.path.tolist()\n",
    "# final_path_li = []\n",
    "# for i in range(len(path_li)):\n",
    "#     if path_li[i].find('/AD/') == -1 and path_li[i].find('/ED/') == -1:\n",
    "#         final_path_li.append(path_li[i])\n",
    "#     else:\n",
    "#         pass\n",
    "# path_li_with_several_condition = final_path_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = final_df[(final_df.result_light_pixel_count>=threshold_light) & (final_df.result_dark_pixel_count<=0.4*threshold_dark)]\n",
    "# path_li_with_several_condition = test_df.path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
